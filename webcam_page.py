import cv2
import streamlit as st
import numpy as np
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration
from emotion_model import detect_face_and_analyze, update_latest_emotion, get_latest_emotion, reset_emotion_state
import app as app
import time
import threading


def show_webcam_page():
    """ì›¹ìº  í˜ì´ì§€ - ì‹¤ì œ ì›¹ìº  ê°ì • ë¶„ì„ êµ¬í˜„"""    
    st.title("ğŸ“¹ ì›¹ìº  ê°ì • ë¶„ì„")
    st.markdown("---")
    
    # ë’¤ë¡œê°€ê¸° ë²„íŠ¼
    if st.button("ğŸ”™ ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        reset_emotion_state()
        st.session_state.current_page = 'main'
        st.rerun()
    
    st.markdown("### ğŸ¥ ì‹¤ì‹œê°„ ì›¹ìº  ë¶„ì„")
    st.info("ì›¹ìº ì„ í—ˆìš©í•´ì£¼ì„¸ìš”. ì–¼êµ´ì´ ê°ì§€ë˜ë©´ ìë™ìœ¼ë¡œ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # WebRTC ì„¤ì •
    RTC_CONFIGURATION = RTCConfiguration(
        {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
    )
    
    class EmotionVideoTransformer(VideoTransformerBase):
        def __init__(self):
            self.frame_count = 0
            
        def transform(self, frame):
            img = frame.to_ndarray(format="bgr24")
            
            # 3í”„ë ˆì„ë§ˆë‹¤ ê°ì • ë¶„ì„ (ì„±ëŠ¥ ìµœì í™”)
            if self.frame_count % 10 == 0:
                emotion, confidence, face_coords = detect_face_and_analyze(img)
                if emotion and confidence > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒë§Œ
                    update_latest_emotion(emotion, confidence)
                
                # ì–¼êµ´ ê°ì§€ëœ ê²½ìš° ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                if face_coords:
                    x, y, w, h = face_coords
                    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
                    
                    # ê°ì • í…ìŠ¤íŠ¸ í‘œì‹œ
                    if emotion != 'neutral' and confidence > 0.5:
                        emotion_text = f"{app.EMOTIONS[emotion]['korean']}: {confidence:.2f}"
                        cv2.putText(img, emotion_text, (x, y-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            self.frame_count += 1
            return img
    
    # WebRTC ìŠ¤íŠ¸ë¦¬ë¨¸
    webrtc_ctx = webrtc_streamer(
        key="emotion-detection",
        video_transformer_factory=EmotionVideoTransformer,
        rtc_configuration=RTC_CONFIGURATION,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )
    
    # í˜„ì¬ ê°ì • ìƒíƒœ í‘œì‹œ
    emotion, confidence = get_latest_emotion()
    
    if emotion and confidence > 0:
        col1, col2 = st.columns(2)
        
        with col1:
            st.success(f"**ê°ì§€ëœ ê°ì •**: {app.EMOTIONS[emotion]['emoji']} {app.EMOTIONS[emotion]['korean']}")
            st.write(f"**ì‹ ë¢°ë„**: {confidence:.2f} ({confidence*100:.1f}%)")
        
        with col2:
            if confidence > 0.6:  # ì‹ ë¢°ë„ 60% ì´ìƒì¼ ë•Œë§Œ ê²°ê³¼ í˜ì´ì§€ ì´ë™ í—ˆìš©
                if st.button("ğŸ“Š ì´ ê²°ê³¼ë¡œ ì´ë™í•˜ê¸°", key="goto_result"):
                    st.session_state.selected_emotion = emotion
                    st.session_state.current_page = 'result'
                    st.rerun()
            else:
                st.warning("ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì–¼êµ´ì„ ë” ëª…í™•í•˜ê²Œ ë³´ì—¬ì£¼ì„¸ìš”.")
    
    else:
        st.info("ì–¼êµ´ì„ ì¹´ë©”ë¼ì— ë§ì¶°ì£¼ì„¸ìš”. ê°ì • ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ì‚¬ìš© ì•ˆë‚´
    with st.expander("ğŸ“‹ ì‚¬ìš© ì•ˆë‚´"):
        st.write("""
        **ì›¹ìº  ì‚¬ìš© íŒ**:
        - ì–¼êµ´ì´ í™”ë©´ ì¤‘ì•™ì— ì˜¤ë„ë¡ ìœ„ì¹˜í•´ì£¼ì„¸ìš”
        - ì¶©ë¶„í•œ ì¡°ëª…ì„ í™•ë³´í•´ì£¼ì„¸ìš”
        - ì¹´ë©”ë¼ì™€ ì ë‹¹í•œ ê±°ë¦¬(30-50cm)ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”
        - ê°ì • í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ í•´ì£¼ì„¸ìš”
        
        **ì£¼ì˜ì‚¬í•­**:
        - HTTPS í™˜ê²½ì—ì„œë§Œ ì›¹ìº  ì ‘ê·¼ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤
        - ì²˜ìŒ ì‹¤í–‰ ì‹œ ë¸Œë¼ìš°ì €ì—ì„œ ì¹´ë©”ë¼ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤
        - ì‹ ë¢°ë„ 60% ì´ìƒì¼ ë•Œ ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        """)
    
    # í…ŒìŠ¤íŠ¸ìš© ê°ì • ê²°ê³¼ (ì›¹ìº ì´ ì‘ë™í•˜ì§€ ì•Šì„ ë•Œ ëŒ€ì•ˆ)
    st.markdown("---")
    st.markdown("### ğŸ§ª ì›¹ìº ì´ ì‘ë™í•˜ì§€ ì•Šë‚˜ìš”?")
    st.write("í…ŒìŠ¤íŠ¸ìš© ê°ì •ì„ ì„ íƒí•´ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”:")
    
    cols = st.columns(3)
    test_emotions = ['happy', 'sad', 'angry']
    for i, emotion in enumerate(test_emotions):
        with cols[i]:
            if st.button(f"í…ŒìŠ¤íŠ¸: {app.EMOTIONS[emotion]['korean']}", key=f"test_{emotion}"):
                st.session_state.current_page = 'result'
                st.session_state.selected_emotion = emotion
                st.rerun()



emotion_lock = threading.Lock()
emotion_history = []

def update_latest_emotion(emotion, confidence):
    global emotion_history, latest_emotion, latest_confidence
    with emotion_lock:
        latest_emotion = emotion
        latest_confidence = confidence
        # ì‹œê°„ê³¼ í•¨ê»˜ ê¸°ë¡
        emotion_history.append((time.time(), emotion, confidence))
